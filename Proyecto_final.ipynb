{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManuJLV/PracticasIA/blob/main/Proyecto_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai requests streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNtAmJf5JFrf",
        "outputId": "fbc145aa-cb84-4928-e4e3-7d635a17f6aa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.84.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import sys\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "Fv-0S5qWI11_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na_sAXyrLh2f",
        "outputId": "d8173ff3-0bb3-4421-d728-b52946329d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Back-end\n",
        "%%writefile /content/drive/MyDrive/Todo/IA/Generativa/Proyecto_Final/ia_core.py\n",
        "import openai\n",
        "import os\n",
        "import sys\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "# --- Carga de datos y configuración de APIs ---\n",
        "file_path = '/content/drive/MyDrive/Todo/IA/Generativa/Proyecto_Final/df_entrenamiento.csv'\n",
        "raw_lines = open(file_path, 'r', encoding='utf-8').readlines()\n",
        "header = raw_lines[0].strip().split(';')\n",
        "num_cols = len(header)\n",
        "data_lines = raw_lines[1:]\n",
        "corrected_rows = []\n",
        "\n",
        "for line in data_lines:\n",
        "    parts = line.strip().split(';')\n",
        "    if len(parts) == num_cols:\n",
        "        corrected_rows.append(parts)\n",
        "    elif len(parts) > num_cols:\n",
        "        fixed = parts[:4]\n",
        "        extra_fields = len(parts) - num_cols\n",
        "        idea_index = 4\n",
        "        idea_end_index = idea_index + 1 + extra_fields\n",
        "        idea = ';'.join(parts[idea_index:idea_end_index])\n",
        "        rest = parts[idea_end_index:]\n",
        "        fixed.extend([idea] + rest)\n",
        "        corrected_rows.append(fixed if len(fixed) == num_cols else ['ERROR'] * num_cols)\n",
        "    else:\n",
        "        corrected_rows.append(['ERROR'] * num_cols)\n",
        "\n",
        "ejemplos_df = pd.DataFrame(corrected_rows, columns=header)\n",
        "cliente = OpenAI(api_key='API_KEY_OPEN_AI')\n",
        "genai.configure(api_key='API_KEY_GOOGLE_GENAI')\n",
        "def evaluar_idea_con_modelos(idea, tipo_negocio, tipo_contenido, publico_objetivo, objetivo_contenido):\n",
        "    # Construcción del prompt\n",
        "    prompt = f\"\"\"\n",
        "Eres un experto en marketing digital y redacción publicitaria. Tu tarea es evaluar una idea generada por una IA para una publicación en redes sociales. Evalúa cada criterio de forma objetiva en una escala del 0 al 5, donde:\n",
        "\n",
        "- 0 = completamente ausente\n",
        "- 1 = muy deficiente\n",
        "- 2 = deficiente\n",
        "- 3 = aceptable\n",
        "- 4 = bueno\n",
        "- 5 = excelente\n",
        "\n",
        "### Parámetros de entrada:\n",
        "- Tipo de negocio: {tipo_negocio}\n",
        "- Tipo de contenido: {tipo_contenido}\n",
        "- Público objetivo: {publico_objetivo}\n",
        "- Objetivo del contenido: {objetivo_contenido}\n",
        "\n",
        "### Texto generado por IA:\n",
        "\"{idea}\"\n",
        "\n",
        "### Criterios de evaluación:\n",
        "1. **Claridad**: ¿El mensaje se comunica de forma clara, sin ambigüedades ni confusión?\n",
        "2. **Alineación con el negocio**: ¿El contenido refleja adecuadamente la naturaleza del negocio?¿Está contextualizada al tipo de producto o servicio?\n",
        "3. **Conexión con el público objetivo**: ¿La idea utiliza lenguaje, referencias o tono adecuados al público definido?¿Apela a intereses, emociones o necesidades del público?\n",
        "4. **Cumplimiento del enfoque del contenido**: ¿La idea es coherente con el tipo de contenido indicado (ej. promocional, educativo)?¿La idea cumple con el objetivo planteado?\n",
        "5. **Tono auténtico y adaptado**: ¿Se percibe una voz natural, cercana, adecuada al tipo de negocio?¿Evita frases genéricas o forzadas?\n",
        "6. **Llamado a la acción (si corresponde)**: ¿Existe un llamado relevante, específico y útil para motivar acción por parte del usuario si corresponde?\n",
        "7. **Originalidad y precisión**: ¿Evita frases genéricas, clichés, pleonasmos y redundancias innecesarias?\n",
        "\n",
        "### Formato de respuesta:\n",
        "Luego de puntuar cada criterio de evaluación, devuelve únicamente el puntaje global de la idea en formato JSON.\n",
        "{{\n",
        "  \"puntaje_global\": float\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "    puntaje_gpt = None\n",
        "    puntaje_gemini = None\n",
        "\n",
        "    # Evaluación con OpenAI GPT\n",
        "    try:\n",
        "        response_openai = cliente.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.4,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        evaluacion_gpt_str = response_openai.choices[0].message.content.strip()\n",
        "        evaluacion_gpt = json.loads(evaluacion_gpt_str)\n",
        "        puntaje_gpt = evaluacion_gpt.get(\"puntaje_global\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during OpenAI evaluation: {e}\")\n",
        "\n",
        "    # Evaluación con Gemini\n",
        "    try:\n",
        "        response_gemini = genai.generate_content(prompt)\n",
        "        evaluacion_gemini_str = response_gemini.text.strip()\n",
        "        # Clean up the Gemini response string to ensure it's valid JSON\n",
        "        evaluacion_gemini_str = re.sub(r'```json\\n', '', evaluacion_gemini_str)\n",
        "        evaluacion_gemini_str = re.sub(r'\\n```', '', evaluacion_gemini_str)\n",
        "        evaluacion_gemini = json.loads(evaluacion_gemini_str)\n",
        "        puntaje_gemini = evaluacion_gemini.get(\"puntaje_global\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Gemini evaluation: {e}\")\n",
        "\n",
        "    # Cálculo del promedio si ambas evaluaciones son válidas\n",
        "    if puntaje_gpt is not None and puntaje_gemini is not None:\n",
        "        promedio = round((puntaje_gpt + puntaje_gemini) / 2, 2)\n",
        "    else:\n",
        "        promedio = None\n",
        "\n",
        "    return promedio\n",
        "\n",
        "def generar_idea_completa(tipo_negocio, tipo_contenido, publicos_objetivos, tipo_objetivo):\n",
        "    if cliente is None:\n",
        "        return \"La clave de OpenAI no está configurada. No se puede generar la idea.\", None\n",
        "\n",
        "    ejemplos_positivos = \"\"\n",
        "    ejemplos_negativos = \"\"\n",
        "\n",
        "    if ejemplos_df is not None:\n",
        "        ejemplos_buenos = ejemplos_df[\n",
        "            (ejemplos_df[\"tipo_negocio\"] == tipo_negocio) &\n",
        "            (ejemplos_df[\"tipo_contenido\"] == tipo_contenido) &\n",
        "            (ejemplos_df[\"aprobado\"] == True)\n",
        "        ].head(2)\n",
        "\n",
        "        for _, fila in ejemplos_buenos.iterrows():\n",
        "            ejemplos_positivos += f\"- \\\"{fila['idea']}\\\"\\n\"\n",
        "\n",
        "        ejemplos_malos = ejemplos_df[\n",
        "            (ejemplos_df[\"tipo_negocio\"] == tipo_negocio) &\n",
        "            (ejemplos_df[\"tipo_contenido\"] == tipo_contenido) &\n",
        "            (ejemplos_df[\"aprobado\"] == False)\n",
        "        ].head(2)\n",
        "\n",
        "        for _, fila in ejemplos_malos.iterrows():\n",
        "            ejemplos_negativos += f\"- \\\"{fila['idea']}\\\"\\n\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Actúa como un experto en marketing digital. Tu tarea es generar un texto publicitario breve (máx. 5 oraciones), creativo y original.\n",
        "    Contexto:\n",
        "      Tipo de negocio: {tipo_negocio}\n",
        "      Enfoque del contenido: {tipo_contenido}\n",
        "      Públicos objetivos: {publicos_objetivos}\n",
        "      Objetivo del contenido: {tipo_objetivo}\n",
        "    Requisitos:\n",
        "      Debe ser clara, atractiva y adaptada. Sin clichés ni redundancias.\n",
        "    --- Ejemplos de Ideas Exitosas ---\n",
        "    {ejemplos_positivos}\n",
        "    --- Ejemplos de Ideas a Evitar ---\n",
        "    {ejemplos_negativos}\n",
        "    Ahora, genera la nueva idea:\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = cliente.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=160,\n",
        "            temperature=0.7,\n",
        "        )\n",
        "        idea = response.choices[0].message.content.strip()\n",
        "        promedio = evaluar_idea_con_modelos(idea, tipo_negocio, tipo_contenido, publicos_objetivos, tipo_objetivo)\n",
        "        return idea, promedio # Return only the idea and the average score\n",
        "    except Exception as e:\n",
        "        return f\"Error al generar la idea: {e}\", None # Return error message and None for average score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZowcIJvApNU4",
        "outputId": "6eda7012-0aa5-4189-9399-7ebd5da118b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/Todo/IA/Generativa/Proyecto_Final/ia_core.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **APLICACION EN STREAMLIT**"
      ],
      "metadata": {
        "id": "7qEfIZRySwSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# Importa la función desde tu módulo de backend ia_core.py\n",
        "import openai\n",
        "import os\n",
        "import sys\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "# Add the current directory to the Python path\n",
        "sys.path.append('/content/drive/MyDrive/Todo/IA/Generativa/Proyecto_Final')\n",
        "\n",
        "from ia_core import generar_idea_completa\n",
        "\n",
        "# --- 1. Configuración de la UI (Frontend) ---\n",
        "st.set_page_config(\n",
        "    page_title=\"Generador de Ideas IA para Redes Sociales\",\n",
        "    page_icon=\"💡\",\n",
        "    layout=\"centered\",\n",
        "    initial_sidebar_state=\"collapsed\"\n",
        ")\n",
        "\n",
        "st.title(\"✨ Generador de Ideas IA para Redes Sociales ✨\")\n",
        "st.markdown(\"Crea ideas de contenido atractivas y validadas para tu negocio.\")\n",
        "\n",
        "# --- 2. Entradas de Usuario ---\n",
        "with st.expander(\"Parámetros de la Idea\", expanded=True):\n",
        "    tipo_negocio = st.text_input(\"Tipo de negocio (ej: Cafetería local, Consultoría IT)\", \"Cafetería local\")\n",
        "    tipo_contenido = st.selectbox(\"Tipo de contenido\", [\"Promocional\", \"Educativo\", \"Interactivo\", \"Lanzamiento de Producto\"], index=0)\n",
        "    publicos_objetivos = st.text_input(\"Público(s) objetivo (ej: Jóvenes universitarios, PYMES)\", \"Jóvenes universitarios\")\n",
        "    tipo_objetivo = st.selectbox(\"Objetivo del contenido\", [\"Aumentar visitas\", \"Generar leads\", \"Construir marca\", \"Educación del cliente\", \"Aumentar ventas\"], index=0)\n",
        "\n",
        "# --- 3. Generación y Evaluación de la Idea ---\n",
        "if st.button(\"🚀 Generar  Idea\", help=\"Haz clic para que la IA genere y valide tu idea.\"):\n",
        "    if not all([tipo_negocio, tipo_contenido, publicos_objetivos, tipo_objetivo]):\n",
        "        st.warning(\"Por favor, rellena todos los campos para generar una idea.\")\n",
        "    else:\n",
        "        with st.spinner(\"🧠 Pensando... ¡Generando y evaluando tu idea con IA! Esto puede tomar unos segundos...\"):\n",
        "            try:\n",
        "                idea_generada, puntaje_promedio = generar_idea_completa(tipo_negocio, tipo_contenido, publicos_objetivos, tipo_objetivo)\n",
        "                #parsear puntaje promedio a float\n",
        "                #puntaje_promedio = float(puntaje_promedio)\n",
        "                # Always display the generated idea if it's not None or an empty string\n",
        "                if idea_generada and idea_generada != \"No se pudo generar una idea.\":\n",
        "                    st.text_area(\"✨ Tu Idea de Contenido ✨\", value=idea_generada, height=200, help=\"Puedes copiar esta idea directamente.\")\n",
        "                    #st.success(f\"✅ ¡Idea generada y aprobada! (Puntaje promedio: ** {puntaje_promedio:.2f} **) ✨\")\n",
        "                    st.info(\"💡 Consejo: Esta idea ha pasado nuestra validación de calidad. ¡Pruébala!\")\n",
        "\n",
        "                else:\n",
        "                    st.error(\"❌ No se logró generar una idea. Considera ajustar los parámetros o revisar los ejemplos de entrenamiento.\")\n",
        "                    # If idea_generada contains an error message from the backend, display it\n",
        "                    if idea_generada and \"Error al generar la idea:\" in idea_generada:\n",
        "                         st.text_area(\"Resultado del Intento (si hubo error)\", value=idea_generada, height=100)\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                st.exception(f\"Ocurrió un error inesperado durante la generación/evaluación: {e}\")\n",
        "\n",
        "# --- 4. Sección de Información y Soporte (Parte del Plan de Acceso y Soporte) ---\n",
        "st.sidebar.title(\"Ayuda y Soporte\")\n",
        "st.sidebar.info(\n",
        "    \"\"\"\n",
        "    Este generador de ideas utiliza modelos avanzados de Inteligencia Artificial para crear\n",
        "    contenido publicitario.\n",
        "    - **¿Dudas?** Visita nuestra [documentación](link_a_documentacion_futura).\n",
        "    - **Soporte:** Contacta a soporte@tuempresa.com\n",
        "    - **Acerca de:** Versión 1.0.0 (Beta)\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# --- 5. Footer (Opcional, parte de branding/información) ---\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"Creado por Andrea Cuatindioy Ortiz y Manuel López Valencia  ¡Todos los derechos reservados 2025!\")"
      ],
      "metadata": {
        "id": "Z6XDwjTUfjwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b386cbf-1dd8-40f1-aef4-28c1ace97158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "source": [
        "ngrok_token = \"YOUR_NGROK_AUTHTOKEN\"\n",
        "if ngrok_token:\n",
        "    ngrok.set_auth_token(ngrok_token)\n",
        "    print(\"Ngrok authentication token set successfully.\")\n",
        "else:\n",
        "    raise ValueError(\"El authtoken de ngrok no está definido correctamente.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "qseyF6mJwO0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb1f287-837a-444e-c29d-3a8bb55052b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok authentication token set successfully.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# Asigna el token a pyngrok\n",
        "os.environ[\"NGROK_AUTH_TOKEN\"] = \"2y1HagZ8t6JXkyTdInBbXnLGjRN_5AtgCHYqYmwnYYBnH5BWR\"\n",
        "ngrok.set_auth_token(os.environ[\"NGROK_AUTH_TOKEN\"])\n",
        "\n",
        "# Kill any existing ngrok tunnels to avoid hitting the limit\n",
        "ngrok.kill()\n",
        "\n",
        "# Start the Streamlit app in the background\n",
        "!streamlit run app.py &>/content/logs.txt &\n",
        "\n",
        "# Connect ngrok to the Streamlit port (8501)\n",
        "# Pass the address directly as the first argument\n",
        "public_url = ngrok.connect(\"8501\")\n",
        "print(f\"Tu app está corriendo en: {public_url}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ee3HxupGqYDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc03044-ff29-46f1-f714-ce7f1ad11541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tu app está corriendo en: NgrokTunnel: \"https://203f-130-211-120-236.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py --server.port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM--BrC5Rln3",
        "outputId": "bbaa4fa2-7ceb-4ac2-d530-d03bcddd35e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "2025-06-10 15:43:21.566 Port 8501 is already in use\n"
          ]
        }
      ]
    }
  ]
}